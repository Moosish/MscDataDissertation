{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/statsbomb/open-data.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evZ4iw_1r_vg",
        "outputId": "7e8a78f5-3df0-4733-9314-16e69538d158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'open-data'...\n",
            "remote: Enumerating objects: 49843, done.\u001b[K\n",
            "remote: Counting objects: 100% (5351/5351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1332/1332), done.\u001b[K\n",
            "remote: Total 49843 (delta 5243), reused 4097 (delta 3999), pack-reused 44492 (from 1)\u001b[K\n",
            "Receiving objects: 100% (49843/49843), 6.45 GiB | 17.67 MiB/s, done.\n",
            "Resolving deltas: 100% (46913/46913), done.\n",
            "Updating files: 100% (7246/7246), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery pandas scikit-learn Flask joblib flask-cors statsbombpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpA545H0jzRc",
        "outputId": "5fe45533-a0c9-43b9-d9ba-6cb1327163b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting statsbombpy\n",
            "  Downloading statsbombpy-1.13.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (2.19.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\n",
            "Collecting requests-cache (from statsbombpy)\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from statsbombpy) (7.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.24.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.7.4)\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect->statsbombpy) (10.3.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect->statsbombpy) (4.3.0)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache->statsbombpy) (24.2.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache->statsbombpy)\n",
            "  Downloading cattrs-24.1.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache->statsbombpy) (4.2.2)\n",
            "Collecting url-normalize>=1.4 (from requests-cache->statsbombpy)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache->statsbombpy) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache->statsbombpy) (4.12.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.0)\n",
            "Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
            "Downloading statsbombpy-1.13.1-py3-none-any.whl (16 kB)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: url-normalize, cattrs, requests-cache, statsbombpy, flask-cors\n",
            "Successfully installed cattrs-24.1.0 flask-cors-4.0.1 requests-cache-1.2.1 statsbombpy-1.13.1 url-normalize-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Path to the directory containing the event files\n",
        "event_files_path = '/content/open-data/data/events'\n",
        "\n",
        "# Function to load and process each event file\n",
        "def process_event_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        events = json.load(f)\n",
        "    return pd.json_normalize(events)\n",
        "\n",
        "# Sample a fraction of the event data (e.g., 10%)\n",
        "sampling_fraction = 0.1\n",
        "\n",
        "# Load and process event data files\n",
        "all_event_data = []\n",
        "for i, file_name in enumerate(os.listdir(event_files_path)):\n",
        "    if file_name.endswith('.json'):\n",
        "        file_path = os.path.join(event_files_path, file_name)\n",
        "        event_df = process_event_file(file_path)\n",
        "\n",
        "        # Randomly sample a fraction of the data\n",
        "        sampled_df = event_df.sample(frac=sampling_fraction, random_state=42)\n",
        "        all_event_data.append(sampled_df)\n",
        "\n",
        "        # Optionally, break early to limit the data size\n",
        "        if i >= 20:  # Adjust this limit based on RAM availability\n",
        "            break\n",
        "\n",
        "# Concatenate all event data into a single DataFrame\n",
        "all_event_data_df = pd.concat(all_event_data, ignore_index=True)\n",
        "print(f\"Total events loaded: {len(all_event_data_df)}\")\n",
        "\n",
        "# Function to create features for model training\n",
        "def create_features(event_df):\n",
        "    # Initialize a dictionary to store player statistics\n",
        "    player_stats = {}\n",
        "\n",
        "    # Loop through each event to accumulate statistics\n",
        "    for idx, row in event_df.iterrows():\n",
        "        player_id = row.get('player.id')\n",
        "        if not player_id:\n",
        "            continue  # Skip events without a player\n",
        "\n",
        "        if player_id not in player_stats:\n",
        "            player_stats[player_id] = {'total_passes': 0, 'total_shots': 0, 'total_fouls': 0}\n",
        "\n",
        "        event_type = row['type.name']\n",
        "        if event_type == 'Pass':\n",
        "            player_stats[player_id]['total_passes'] += 1\n",
        "        elif event_type == 'Shot':\n",
        "            player_stats[player_id]['total_shots'] += 1\n",
        "        elif event_type == 'Foul Committed':\n",
        "            player_stats[player_id]['total_fouls'] += 1\n",
        "\n",
        "    # Create feature vectors for the model\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for idx, row in event_df.iterrows():\n",
        "        player_id = row.get('player.id')\n",
        "        if player_id and player_id in player_stats:\n",
        "            feature_vector = [\n",
        "                row.get('minute', 0),  # Numeric feature\n",
        "                player_stats[player_id]['total_passes'],  # Numeric feature\n",
        "                player_stats[player_id]['total_shots'],  # Numeric feature\n",
        "                player_stats[player_id]['total_fouls']   # Numeric feature\n",
        "            ]\n",
        "            features.append(feature_vector)\n",
        "\n",
        "            # Label: 1 if the event is a 'Tactical Shift', else 0\n",
        "            label = 1 if row['type.name'] == 'Tactical Shift' else 0\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Apply feature creation to the DataFrame\n",
        "X, y = create_features(all_event_data_df)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a DecisionTreeClassifier model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy for 'Tactical Shift' Prediction:\", accuracy)\n",
        "\n",
        "# Save the model for later use\n",
        "import joblib\n",
        "joblib.dump(model, 'tactical_shift_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDGIvDy11NVF",
        "outputId": "2356ca07-d612-44a1-9736-4b4c4516011a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total events loaded: 7677\n",
            "Model Accuracy for 'Tactical Shift' Prediction: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tactical_shift_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGTWmJOojS_D",
        "outputId": "580d512c-17e9-4ca6-c192-a716b0a1b4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "import joblib\n",
        "joblib.dump(model, 'tactical_shift_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHBx49Yx1O6w",
        "outputId": "f1102c41-a463-4dd1-f297-b4a2ba98a7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tactical_shift_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import numpy as np\n",
        "from flask_cors import CORS\n",
        "import logging\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "# Load the trained model\n",
        "try:\n",
        "    model = joblib.load('tactical_shift_model.pkl')\n",
        "    logging.info(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error loading model: {e}\")\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable CORS for all routes\n",
        "\n",
        "@app.route('/predict-tactical-shift', methods=['POST'])\n",
        "def predict_tactical_shift():\n",
        "    if request.method == 'OPTIONS':\n",
        "        response = jsonify({})\n",
        "        response.headers.add(\"Access-Control-Allow-Origin\", \"*\")\n",
        "        response.headers.add(\"Access-Control-Allow-Headers\", \"Content-Type\")\n",
        "        response.headers.add(\"Access-Control-Allow-Methods\", \"POST, OPTIONS\")\n",
        "        return response\n",
        "\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        current_events = data.get(\"events\")\n",
        "\n",
        "        # Preprocess the events (this should match your training process)\n",
        "        X = preprocess_events(current_events)\n",
        "\n",
        "        # Debugging: Print out the shape of X to ensure it is as expected\n",
        "        logging.debug(f\"Input features shape: {X.shape}\")\n",
        "\n",
        "        # Get prediction probabilities\n",
        "        proba = model.predict_proba(X)\n",
        "\n",
        "        # Debugging: Print out the proba array to understand what predictions are being made\n",
        "        logging.debug(f\"Prediction probabilities: {proba}\")\n",
        "\n",
        "        # Handle the case where only one probability is returned for each prediction\n",
        "        if proba.shape[1] == 1:\n",
        "            # Binary classification: only one probability returned (for the positive class)\n",
        "            result = {\n",
        "                \"team_1_tactical_shift_probability\": proba[0][0],  # Probability for the first team\n",
        "                \"team_2_tactical_shift_probability\": proba[1][0] if len(proba) > 1 else None  # Check if there's a second team\n",
        "            }\n",
        "        else:\n",
        "            # If two probabilities are returned (for both classes)\n",
        "            result = {\n",
        "                \"team_1_tactical_shift_probability\": proba[0][1],  # Probability for the first team\n",
        "                \"team_2_tactical_shift_probability\": proba[1][1] if len(proba) > 1 else None  # Check if there's a second team\n",
        "            }\n",
        "\n",
        "        return jsonify(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during prediction: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "def preprocess_events(events):\n",
        "    # Convert the event data into the format your model expects\n",
        "    try:\n",
        "        # Initialize a list for storing features\n",
        "        features = []\n",
        "\n",
        "        for event in events:\n",
        "            # Extract relevant features that match the model's training process\n",
        "            # Adjust this to match exactly the features your model was trained on\n",
        "\n",
        "            event_type = event['type'].get('name', 'Unknown')\n",
        "            minute = event.get('minute', 0)\n",
        "            second = event.get('second', 0)\n",
        "            team = event['team'].get('name', 'Unknown')\n",
        "\n",
        "            # Assuming that only 4 features were used in training, select only 4\n",
        "            feature_vector = [\n",
        "                minute,             # Numeric feature\n",
        "                second,             # Numeric feature\n",
        "                len(event_type),    # Example of a categorical feature converted to numeric\n",
        "                len(team)           # Another categorical feature converted to numeric\n",
        "            ]\n",
        "\n",
        "            # Append the feature vector to the list\n",
        "            features.append(feature_vector)\n",
        "\n",
        "        # Convert the list to a numpy array for model input\n",
        "        X = np.array(features)\n",
        "\n",
        "        # Ensure the array is 2D even if there's only one sample\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        # Log the feature vectors for debugging\n",
        "        logging.debug(f\"Feature vectors: {X}\")\n",
        "\n",
        "        return X\n",
        "\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"Missing expected feature: {e}\")\n",
        "        raise e\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in preprocessing: {e}\")\n",
        "        raise e\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=8080, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDJLd0V5jUiC",
        "outputId": "089da85a-b9d6-42dc-9233-6463c8494f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Dockerfile\n",
        "# Use an official Python runtime as a parent image\n",
        "FROM python:3.8-slim\n",
        "\n",
        "# Set the working directory in the container\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy the current directory contents into the container\n",
        "COPY . /app\n",
        "\n",
        "# Install any needed packages specified in requirements.txt\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Expose port 8080 for Flask\n",
        "EXPOSE 8080\n",
        "\n",
        "# Define environment variable for Flask\n",
        "ENV FLASK_APP=app.py\n",
        "ENV FLASK_RUN_HOST=0.0.0.0\n",
        "ENV FLASK_ENV=production\n",
        "\n",
        "# Run the Flask app\n",
        "CMD [\"flask\", \"run\", \"--port=8080\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM-ihub_jXY0",
        "outputId": "1022466d-bc2f-4c44-cb3c-9324568d94cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "flask\n",
        "flask-cors\n",
        "joblib\n",
        "numpy\n",
        "pandas\n",
        "scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTPCUDLe1xVQ",
        "outputId": "e629d353-c8a7-41f1-d441-d703ff5cae28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YHSt51K15-r",
        "outputId": "a042a113-4593-4c25-932e-9c0805f80b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=kQPUL0V3CLxUEqgmYIzzuiYWQ9PZfa&prompt=consent&token_usage=remote&access_type=offline&code_challenge=Xfm9UmpOIW12UYBD6Vz__0Aja0nQ5Uf9vi0nIPRxoLY&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AQlEd8yaDOe_TflaRV1z0o23zU0uLeoN4e84tCOgdbdsJKcknCoCbo6DUrXG5PQAiooJHw\n",
            "\n",
            "You are now logged in as [thomasgeorgepasley@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project polar-ensign-432610-t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAVt303F2EZq",
        "outputId": "208da673-6013-4e16-e75e-e6dd8bb29329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud builds submit --tag gcr.io/polar-ensign-432610-t7/tactical-model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up8ss-Hq16bA",
        "outputId": "d5e6dc7c-5bd7-4c1a-c410-7a6ce639e97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating temporary archive of 4 file(s) totalling 6.0 KiB before compression.\n",
            "Uploading tarball of [.] to [gs://polar-ensign-432610-t7_cloudbuild/source/1724870649.343608-89d80a9e360440a895d6aba15feea0a9.tgz]\n",
            "Created [https://cloudbuild.googleapis.com/v1/projects/polar-ensign-432610-t7/locations/global/builds/9dc9682f-c737-48b8-a027-a8dbc0a1e992].\n",
            "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/9dc9682f-c737-48b8-a027-a8dbc0a1e992?project=116084333061 ].\n",
            "Waiting for build to complete. Polling interval: 1 second(s).\n",
            " REMOTE BUILD OUTPUT\n",
            "starting build \"9dc9682f-c737-48b8-a027-a8dbc0a1e992\"\n",
            "\n",
            "FETCHSOURCE\n",
            "Fetching storage object: gs://polar-ensign-432610-t7_cloudbuild/source/1724870649.343608-89d80a9e360440a895d6aba15feea0a9.tgz#1724870650013844\n",
            "Copying gs://polar-ensign-432610-t7_cloudbuild/source/1724870649.343608-89d80a9e360440a895d6aba15feea0a9.tgz#1724870650013844...\n",
            "/ [1 files][  2.9 KiB/  2.9 KiB]                                                \n",
            "Operation completed over 1 objects/2.9 KiB.\n",
            "BUILD\n",
            "Already have image (with digest): gcr.io/cloud-builders/docker\n",
            "Sending build context to Docker daemon  11.26kB\n",
            "Step 1/9 : FROM python:3.8-slim\n",
            "3.8-slim: Pulling from library/python\n",
            "e4fff0779e6d: Already exists\n",
            "4a5c74102edc: Pulling fs layer\n",
            "8d7f4eef7e05: Pulling fs layer\n",
            "120a794db9c9: Pulling fs layer\n",
            "188f8c4ef238: Pulling fs layer\n",
            "188f8c4ef238: Waiting\n",
            "120a794db9c9: Download complete\n",
            "4a5c74102edc: Verifying Checksum\n",
            "4a5c74102edc: Download complete\n",
            "188f8c4ef238: Verifying Checksum\n",
            "188f8c4ef238: Download complete\n",
            "4a5c74102edc: Pull complete\n",
            "8d7f4eef7e05: Download complete\n",
            "8d7f4eef7e05: Pull complete\n",
            "120a794db9c9: Pull complete\n",
            "188f8c4ef238: Pull complete\n",
            "Digest: sha256:f8b4609a66cdaa133fa57e2ca8e2f03de2ebb44ffefb4c0b8b2de782aefca4a1\n",
            "Status: Downloaded newer image for python:3.8-slim\n",
            " ---> e7fd04b8ffc7\n",
            "Step 2/9 : WORKDIR /app\n",
            " ---> Running in 32e86b8b8092\n",
            "Removing intermediate container 32e86b8b8092\n",
            " ---> 79075a8278e8\n",
            "Step 3/9 : COPY . /app\n",
            " ---> ec49aa31d476\n",
            "Step 4/9 : RUN pip install --no-cache-dir -r requirements.txt\n",
            " ---> Running in 1ba344850036\n",
            "Collecting flask\n",
            "  Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 4.7 MB/s eta 0:00:00\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.8/301.8 kB 31.8 MB/s eta 0:00:00\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 152.1 MB/s eta 0:00:00\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 133.5 MB/s eta 0:00:00\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.1/11.1 MB 150.9 MB/s eta 0:00:00\n",
            "Collecting blinker>=1.6.2\n",
            "  Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
            "Collecting importlib-metadata>=3.6.0\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting Werkzeug>=3.0.0\n",
            "  Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 227.6/227.6 kB 178.0 MB/s eta 0:00:00\n",
            "Collecting Jinja2>=3.1.2\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.3/133.3 kB 161.4 MB/s eta 0:00:00\n",
            "Collecting click>=8.1.3\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 162.3 MB/s eta 0:00:00\n",
            "Collecting itsdangerous>=2.1.2\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 177.8 MB/s eta 0:00:00\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.4/345.4 kB 181.9 MB/s eta 0:00:00\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 505.5/505.5 kB 179.0 MB/s eta 0:00:00\n",
            "Collecting scipy>=1.5.0\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 151.8 MB/s eta 0:00:00\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.20.1-py3-none-any.whl (9.0 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, zipp, tzdata, threadpoolctl, six, numpy, MarkupSafe, joblib, itsdangerous, click, blinker, Werkzeug, scipy, python-dateutil, Jinja2, importlib-metadata, scikit-learn, pandas, flask, flask-cors\n",
            "Successfully installed Jinja2-3.1.4 MarkupSafe-2.1.5 Werkzeug-3.0.4 blinker-1.8.2 click-8.1.7 flask-3.0.3 flask-cors-4.0.1 importlib-metadata-8.4.0 itsdangerous-2.2.0 joblib-1.4.2 numpy-1.24.4 pandas-2.0.3 python-dateutil-2.9.0.post0 pytz-2024.1 scikit-learn-1.3.2 scipy-1.10.1 six-1.16.0 threadpoolctl-3.5.0 tzdata-2024.1 zipp-3.20.1\n",
            "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "\u001b[0m\u001b[91m\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
            "[notice] To update, run: pip install --upgrade pip\n",
            "\u001b[0mRemoving intermediate container 1ba344850036\n",
            " ---> e9367ed3d60e\n",
            "Step 5/9 : EXPOSE 8080\n",
            " ---> Running in df2567a2dbcb\n",
            "Removing intermediate container df2567a2dbcb\n",
            " ---> 584a028cf12c\n",
            "Step 6/9 : ENV FLASK_APP=app.py\n",
            " ---> Running in ef189efb1e53\n",
            "Removing intermediate container ef189efb1e53\n",
            " ---> 9512dc503de3\n",
            "Step 7/9 : ENV FLASK_RUN_HOST=0.0.0.0\n",
            " ---> Running in d7eb63c2164d\n",
            "Removing intermediate container d7eb63c2164d\n",
            " ---> b6695f948ce1\n",
            "Step 8/9 : ENV FLASK_ENV=production\n",
            " ---> Running in c66879de2606\n",
            "Removing intermediate container c66879de2606\n",
            " ---> d86e369b54d9\n",
            "Step 9/9 : CMD [\"flask\", \"run\", \"--port=8080\"]\n",
            " ---> Running in c188f9d554ce\n",
            "Removing intermediate container c188f9d554ce\n",
            " ---> af984f037e84\n",
            "Successfully built af984f037e84\n",
            "Successfully tagged gcr.io/polar-ensign-432610-t7/tactical-model:latest\n",
            "PUSH\n",
            "Pushing gcr.io/polar-ensign-432610-t7/tactical-model\n",
            "The push refers to repository [gcr.io/polar-ensign-432610-t7/tactical-model]\n",
            "43d1bf070759: Preparing\n",
            "52aa639bd4c8: Preparing\n",
            "7a45eeb1a2ae: Preparing\n",
            "ea3ca52555d9: Preparing\n",
            "c051c8ddf0e4: Preparing\n",
            "3fd23da07c85: Preparing\n",
            "d459f4cb7e83: Preparing\n",
            "9853575bc4f9: Preparing\n",
            "3fd23da07c85: Waiting\n",
            "d459f4cb7e83: Waiting\n",
            "9853575bc4f9: Waiting\n",
            "c051c8ddf0e4: Layer already exists\n",
            "ea3ca52555d9: Layer already exists\n",
            "3fd23da07c85: Layer already exists\n",
            "d459f4cb7e83: Layer already exists\n",
            "9853575bc4f9: Layer already exists\n",
            "7a45eeb1a2ae: Pushed\n",
            "52aa639bd4c8: Pushed\n",
            "43d1bf070759: Pushed\n",
            "latest: digest: sha256:fa8cb2382a067e425be6c6abd6d47d79e3314a86dadd1bd4ef984582cd2944b6 size: 1997\n",
            "DONE\n",
            "\n",
            "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                IMAGES                                                  STATUS\n",
            "9dc9682f-c737-48b8-a027-a8dbc0a1e992  2024-08-28T18:44:10+00:00  1M7S      gs://polar-ensign-432610-t7_cloudbuild/source/1724870649.343608-89d80a9e360440a895d6aba15feea0a9.tgz  gcr.io/polar-ensign-432610-t7/tactical-model (+1 more)  SUCCESS\n"
          ]
        }
      ]
    }
  ]
}